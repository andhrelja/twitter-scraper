{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014622926712036133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json",
       "rate": null,
       "total": 28918,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6accee4f77049dc9a08f54eec2ec049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.4.1.json:   0%|   â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-29 15:02:14 INFO: Downloading default packages for language: en (English) ...\n",
      "2022-10-29 15:02:15 INFO: File exists: /home/milky/stanza_resources/en/default.zip\n",
      "2022-10-29 15:02:19 INFO: Finished downloading models and saved to /home/milky/stanza_resources.\n",
      "Downloading https://raw.githubusercontent.com/clarinsi/classla-resources/main/resources_1.0.2.json: 10.5kB [00:00, 7.07MB/s]                   \n",
      "2022-10-29 15:02:19 INFO: Downloading these customized packages for language: sl (Slovenian)...\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | standard |\n",
      "| pos       | standard |\n",
      "| lemma     | standard |\n",
      "| depparse  | standard |\n",
      "| ner       | standard |\n",
      "| pretrain  | standard |\n",
      "========================\n",
      "\n",
      "2022-10-29 15:02:20 INFO: File exists: /home/milky/classla_resources/sl/pos/standard.pt.\n",
      "2022-10-29 15:02:20 INFO: File exists: /home/milky/classla_resources/sl/lemma/standard.pt.\n",
      "2022-10-29 15:02:20 INFO: File exists: /home/milky/classla_resources/sl/depparse/standard.pt.\n",
      "2022-10-29 15:02:20 INFO: File exists: /home/milky/classla_resources/sl/ner/standard.pt.\n",
      "2022-10-29 15:02:20 INFO: File exists: /home/milky/classla_resources/sl/pretrain/standard.pt.\n",
      "2022-10-29 15:02:20 INFO: Finished downloading models and saved to /home/milky/classla_resources.\n",
      "Downloading https://raw.githubusercontent.com/clarinsi/classla-resources/main/resources_1.0.2.json: 10.5kB [00:00, 9.41MB/s]                   \n",
      "2022-10-29 15:02:21 INFO: Downloading these customized packages for language: hr (Croatian)...\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | standard |\n",
      "| pos       | standard |\n",
      "| lemma     | standard |\n",
      "| depparse  | standard |\n",
      "| ner       | standard |\n",
      "| pretrain  | standard |\n",
      "========================\n",
      "\n",
      "2022-10-29 15:02:21 INFO: File exists: /home/milky/classla_resources/hr/pos/standard.pt.\n",
      "2022-10-29 15:02:21 INFO: File exists: /home/milky/classla_resources/hr/lemma/standard.pt.\n",
      "2022-10-29 15:02:21 INFO: File exists: /home/milky/classla_resources/hr/depparse/standard.pt.\n",
      "2022-10-29 15:02:22 INFO: File exists: /home/milky/classla_resources/hr/ner/standard.pt.\n",
      "2022-10-29 15:02:22 INFO: File exists: /home/milky/classla_resources/hr/pretrain/standard.pt.\n",
      "2022-10-29 15:02:22 INFO: Finished downloading models and saved to /home/milky/classla_resources.\n",
      "Downloading https://raw.githubusercontent.com/clarinsi/classla-resources/main/resources_1.0.2.json: 10.5kB [00:00, 9.22MB/s]                   \n",
      "2022-10-29 15:02:22 INFO: Downloading these customized packages for language: sr (Serbian)...\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | standard |\n",
      "| pos       | standard |\n",
      "| lemma     | standard |\n",
      "| depparse  | standard |\n",
      "| ner       | standard |\n",
      "| pretrain  | standard |\n",
      "========================\n",
      "\n",
      "2022-10-29 15:02:22 INFO: File exists: /home/milky/classla_resources/sr/pos/standard.pt.\n",
      "2022-10-29 15:02:23 INFO: File exists: /home/milky/classla_resources/sr/lemma/standard.pt.\n",
      "2022-10-29 15:02:23 INFO: File exists: /home/milky/classla_resources/sr/depparse/standard.pt.\n",
      "2022-10-29 15:02:23 INFO: File exists: /home/milky/classla_resources/sr/ner/standard.pt.\n",
      "2022-10-29 15:02:23 INFO: File exists: /home/milky/classla_resources/sr/pretrain/standard.pt.\n",
      "2022-10-29 15:02:23 INFO: Finished downloading models and saved to /home/milky/classla_resources.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] 2022-10-29 15:02:24 discord.client - PyNaCl is not installed, voice will NOT be supported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from twitter_scraper import settings\n",
    "# from twitter_scraper.text.tweets import detect_language\n",
    "from twitter_scraper.text.tweets import get_stemmed_text\n",
    "from twitter_scraper.text.tweets import clean_twitter_text\n",
    "from twitter_scraper.clean.users import USER_DTYPE\n",
    "from twitter_scraper.clean.tweets import TWEET_DTYPE\n",
    "\n",
    "\n",
    "users_df = pd.read_csv(settings.USERS_CSV, dtype=USER_DTYPE)\n",
    "tweets_df = pd.read_csv(settings.TWEETS_CSV, dtype=TWEET_DTYPE)\n",
    "retweets_df = pd.read_csv(settings.EDGES_RETWEETS_CSV)\n",
    "retweets_df = retweets_df.loc[retweets_df['source'] != retweets_df['target']]\n",
    "\n",
    "user_idx = users_df[['user_id', 'screen_name']].set_index('user_id').to_dict()['screen_name']\n",
    "retweets_df['source'] = retweets_df['source'].transform(lambda x: user_idx[x])\n",
    "retweets_df['target'] = retweets_df['target'].transform(lambda x: user_idx[x])\n",
    "retweets_df['full_text'] = retweets_df['full_text'].transform(clean_twitter_text)\n",
    "# retweets_df['langid'] = retweets_df['full_text'].transform(detect_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2022-10-29 15:03:14 langid.langid - initializing identifier\n"
     ]
    }
   ],
   "source": [
    "retweets_df['stemmed_text'] = retweets_df['full_text'].transform(get_stemmed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retweet_tweet_ids = retweets_df.og_tweet_id.value_counts().index\n",
    "retweets_df.og_tweet_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.langid.value_counts()[:15].plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "source_retweets_df = pd.DataFrame(retweets_df.source.value_counts())[:15].join(users_df[['user_id', 'screen_name']].set_index('user_id')).sort_values('source', ascending=False)\n",
    "source_retweets_df.plot.bar(x='screen_name', y='source', rot=30, title='Most retweeted sources', ax=axs[0])\n",
    "\n",
    "target_retweets_df = pd.DataFrame(retweets_df.target.value_counts())[:15].join(users_df[['user_id', 'screen_name']].set_index('user_id')).sort_values('target', ascending=False)\n",
    "target_retweets_df.plot.bar(x='screen_name', y='target', rot=30, title='Most retweeting targets', ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[tweets_df['id'] == str(1501227789437255680)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets_df.loc[retweets_df['source'].isin(source_retweets_df.index) | retweets_df['target'].isin(target_retweets_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "\n",
    "\n",
    "G = nx.from_pandas_edgelist(retweets_df.loc[retweets_df['source'].isin(source_retweets_df.index) | retweets_df['target'].isin(target_retweets_df.index)], edge_attr='rt_time_elapsed_sec')\n",
    "nx.draw_spring(G, node_size=20, ax=ax, labels=user_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(retweets_df, create_using=nx.DiGraph)\n",
    "dg_centrality = nx.degree_centrality(G)\n",
    "dg_centrality = [{'user_id': key, 'user_name': users_df.loc[users_df['user_id'] == key].screen_name.values[0], 'centrality': value} for key, value in dg_centrality.items()]\n",
    "sorted_dg_centrailty = sorted(dg_centrality, key=lambda x: x['centrality'], reverse=True)\n",
    "best_dg_centrality = sorted_dg_centrailty[:10]\n",
    "best_dg_centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twitter_scraper.utils import fileio\n",
    "from twitter_scraper.text.tweets import get_stemmed_text\n",
    "\n",
    "best_dg_centrality_user_ids = [item['user_id'] for item in best_dg_centrality]\n",
    "\n",
    "def get_central_user_tweets():\n",
    "    user_tweet_records = tweets_df[tweets_df['user_id'].isin(best_dg_centrality_user_ids)][['user_id', 'full_text']].to_dict(orient='records')\n",
    "    central_user_tweets = {}\n",
    "    for item in user_tweet_records:\n",
    "        user_id = item['user_id']\n",
    "        if user_id in central_user_tweets:\n",
    "            central_user_tweets[user_id].append(item['full_text'])\n",
    "        else:\n",
    "            central_user_tweets[user_id] = [item['full_text']]\n",
    "    return central_user_tweets\n",
    "\n",
    "\n",
    "central_user_tweets = get_central_user_tweets()\n",
    "most_occuring_keywords = {}\n",
    "for user_id in best_dg_centrality_user_ids:\n",
    "    word_count = most_occuring_keywords.get(user_idx[user_id], {})\n",
    "    for text in central_user_tweets[user_id]:\n",
    "        text = get_stemmed_text(text)\n",
    "        for word in text:\n",
    "            if word in word_count:\n",
    "                word_count[word] += 1\n",
    "            else:\n",
    "                word_count[word] = 1\n",
    "    most_occuring_keywords[user_idx[user_id]] = word_count\n",
    "# fileio.write_content('most_occuring_keywords.json', most_occuring_keywords, 'json')\n",
    "print(most_occuring_keywords[user_idx[user_id]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df[tweets_df['user_id'].isin(best_dg_centrality_user_ids)][['user_id', 'full_text']].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "conn_details = settings.connections['andhrelja']\n",
    "auth = tweepy.OAuthHandler(conn_details['consumer_key'], conn_details['consumer_secret'])\n",
    "auth.set_access_token(conn_details['access_key'], conn_details['access_secret'])\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = api.get_retweets(1555473887336472576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(api.supported_languages()).sort_values('code').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('twitter_scraper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "967e65d78b012836ccc9230f84f154fbeb6a66551d2543767befd0989f69ed55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
