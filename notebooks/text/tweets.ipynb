{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from twitter_scraper import settings\n",
    "from twitter_scraper.clean.tweets import TWEET_DTYPE\n",
    "\n",
    "tweets_df = pd.read_csv(settings.TEXT_TWEETS_CSV, dtype=TWEET_DTYPE)\n",
    "tweets_df['lemmatized'] = tweets_df['lemmatized'].map(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'full_text': 'Oko 50 lijecnika danas je na nasem strucnom skupu razgovaralo o prvoj pomoci u kriznim situacijama. Poruka je jasna - i kao pojedinci i kao zajednica moramo raditi na vlastitoj otpornosti u ovim turbulentnim vremenima. https://t.co/fYIJrU70vY',\n",
       "  'lemmatized': ['lijecnik',\n",
       "   'nas',\n",
       "   'strucan',\n",
       "   'skup',\n",
       "   'prvi',\n",
       "   'pomoka',\n",
       "   'kriznim-situacija',\n",
       "   'poruka',\n",
       "   'jasan',\n",
       "   'pojedinac',\n",
       "   'zajednica',\n",
       "   'vlastit',\n",
       "   'otpornost',\n",
       "   'turbulentan',\n",
       "   'vrijeme']},\n",
       " {'full_text': 'Dragi naÅ¡i darivatelji, hvala vam!â¤ï¸\\nhttps://t.co/M4ptWaq69D https://t.co/rtnDIbs1uG',\n",
       "  'lemmatized': ['drag', 'darivatelj', 'hvala']},\n",
       " {'full_text': 'Pozdrav s jezera Soderica! Od zore smo aktivni, nastavljamo Medjunarodnu terensku vjezbu! ðŸ’ª https://t.co/G1lIPldjH9',\n",
       "  'lemmatized': ['pozdrav',\n",
       "   'jezero',\n",
       "   'soderic',\n",
       "   'zora',\n",
       "   'aktiven',\n",
       "   'medjunaroden',\n",
       "   'terenski',\n",
       "   'vjezb']},\n",
       " {'full_text': 'Gotovo 500 sudionika iz zemlje i svijeta okupilo se na Medjunarodnoj terenskoj vjezbi timova za odgovor na krizne situacije. Satori se jos uvijek dizu, a priprema se i vjezba spasavanja zivota na vodi. https://t.co/cg1TL7MN66',\n",
       "  'lemmatized': ['sudionik',\n",
       "   'zemlja',\n",
       "   'svijet',\n",
       "   'medjunarodni',\n",
       "   'terenski',\n",
       "   'vjezba',\n",
       "   'tim',\n",
       "   'odgovor',\n",
       "   'krizan',\n",
       "   'situacija',\n",
       "   'sator',\n",
       "   'priprema',\n",
       "   'vjezba',\n",
       "   'spasavanje',\n",
       "   'zivot']},\n",
       " {'full_text': 'Danas je Europski dan suzbijanja trgovanja ljudima. Kljucne su preventivne aktivnosti i podizanje svijesti o ovome problemu jer se trgovanje ljudima dogadja svuda oko nas, a najizlozeniji su oni najranjiviji. https://t.co/QryadIBaKx',\n",
       "  'lemmatized': ['europski',\n",
       "   'dan',\n",
       "   'suzbijanje',\n",
       "   'trgovanje',\n",
       "   'Äovjek',\n",
       "   'kljucan',\n",
       "   'preventivan',\n",
       "   'aktivnost',\n",
       "   'podizanje',\n",
       "   'svijest',\n",
       "   'problem',\n",
       "   'trgovanje',\n",
       "   'Äovjek',\n",
       "   'ranjiv']}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[['full_text', 'lemmatized']].head().to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m all_words \u001b[39m=\u001b[39m tweets_df[[\u001b[39m'\u001b[39m\u001b[39mlangid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlemmatized\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mlangid\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39msum()\n\u001b[0;32m----> 2\u001b[0m all_words \u001b[39m=\u001b[39m all_words\u001b[39m.\u001b[39;49mapply(\u001b[39mset\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/Envs/twitter_scraper/lib/python3.8/site-packages/pandas/core/frame.py:9555\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9544\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9546\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9547\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9548\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9553\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9554\u001b[0m )\n\u001b[0;32m-> 9555\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Envs/twitter_scraper/lib/python3.8/site-packages/pandas/core/apply.py:746\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    744\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 746\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/Envs/twitter_scraper/lib/python3.8/site-packages/pandas/core/apply.py:873\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 873\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    875\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/Envs/twitter_scraper/lib/python3.8/site-packages/pandas/core/apply.py:889\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    887\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    888\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    890\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    891\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    892\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    893\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "all_words = tweets_df[['langid', 'lemmatized']].groupby('langid').sum()\n",
    "all_words = all_words.apply(set, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('twitter_scraper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "967e65d78b012836ccc9230f84f154fbeb6a66551d2543767befd0989f69ed55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
